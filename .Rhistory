hist(datos$relig, datos$consci)
plot(gss$relig, gss$consci)
plot(gss$relig, gss$consci)
summary(relig)
summary(consci)
summary(gss$relig)
summary(gss$consci)
by(gss$relig, gss$consci, summary)
_abline
?abline
library("SnowballC", lib.loc="~/R/win-library/3.1") # Provides wordStem() for stemming.
library("RColorBrewer", lib.loc="~/R/win-library/3.1") # Generate palette of colours for plots.
library("ggplot2", lib.loc="~/R/win-library/3.1") # Plot word frequencies.
library("wordcloud", lib.loc="~/R/win-library/3.1")
library("Rgraphviz", lib.loc="~/R/win-library/3.1") # Correlation plots.
cname <- file.path("~", "", "Documentos", "TyP", "txt")
#cname <- file.path(".")
cname
##We can list some of the file names.
length(dir(cname))
dir(cname)
install.packages("SnowballC")
install.packages("RColorBrewer")
install.packages("ggplot2")
install.packages("wordcloud")
install.packages("tm")
library("SnowballC", lib.loc="~/R/win-library/3.1") # Provides wordStem() for stemming.
library("RColorBrewer", lib.loc="~/R/win-library/3.1") # Generate palette of colours for plots.
library("ggplot2", lib.loc="~/R/win-library/3.1") # Plot word frequencies.
library("wordcloud", lib.loc="~/R/win-library/3.1")
library("SnowballC", lib.loc="~/R/win-library/3.1")
library("SnowballC") # Provides wordStem() for stemming.
library("RColorBrewer") # Generate palette of colours for plots.
library("ggplot2") # Plot word frequencies.
library("wordcloud")
library("tm")
docs <- Corpus(DirSource(cname, encoding = "UTF-8"))
docs
class(docs)
class(docs[[1]])
cname <- file.path("~", "", "Documentos", "TyP", "txt")
#cname <- file.path(".")
cname
length(dir(cname))
dir(cname)
docs <- Corpus(DirSource(cname, encoding = "UTF-8"))
docs
class(docs)
class(docs[[1]])
summary(docs)
inspect(docs[1])
for (j in seq(docs))
{
docs[[j]] <- gsub("(", " ", docs[[j]])
docs[[j]] <- gsub(")", " ", docs[[j]])
#        docs[[j]] <- gsub("\\|", " ", docs[[j]])
}
seq(docs)
?gsub
docs[[1]]
docs <- tm_map(docs, tolower)
inspect(docs[1])
docs <- tm_map(docs, removeNumbers)
inspect(docs[1])
docs <- tm_map(docs, removePunctuation)
inspect(docs[1])
?stopwords
?tm_map
getTransformations()
docs <- tm_map(docs, stripWhitespace)
inspect(docs[1])
docs <- tm_map(docs, removeWords, stopwords("spanish"))
inspect(docs[1])
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS")
docs <- tm_map(docs, removeWords, quitarpalabras)
inspect(docs[1])
?stemDocument
getTransformations()
?tm_map
getStemLanguages()
docs2 <- tm_map(docs, stemDocument, language = "spanish")
inspect(docs2[1])
remove(docs2)
tdm <- TermDocumentMatrix(docs)
?TermDocumentMatrix
dtm <- DocumentTermMatrix(docs)
docs <- Corpus(DirSource(cname, encoding = "UTF-8"))
docs <- tm_map(docs, tolower)
docs <- Corpus(DirSource(cname, encoding = "UTF-8"))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation)
# acortar espacios
docs <- tm_map(docs, stripWhitespace)
#Remove Spanish Stop Words
docs <- tm_map(docs, removeWords, stopwords("spanish"))
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS")
docs <- tm_map(docs, removeWords, quitarpalabras)
tdm <- TermDocumentMatrix(docs)
inspect(tdm[5:10, 740:743])
inspect(tdm[5:10, 30:60])
freq <- colSums(as.matrix(tdm))
length(freq)
freq <- rowSums(as.matrix(tdm))
length(freq)
ord <- order(freq)
freq[head(ord)]
freq[tail(ord)]
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS")
docs <- tm_map(docs, removeWords, quitarpalabras)
tdm <- TermDocumentMatrix(docs)
freq <- rowSums(as.matrix(tdm))
length(freq)
ord <- order(freq)
freq[tail(ord)]
freq[tail(ord),10]
freq[tail(ord,10)]
freq[tail(ord,20)]
palabritas <- scan("~//Documentos/quitarpalabras.txt",sep=",")
?scan
palabritas <- scan("~//Documentos/quitarpalabras.txt",sep=",",text)
palabritas <- scan("~//Documentos/quitarpalabras.txt",sep=",what=character)
)
palabritas <- scan("~//Documentos/quitarpalabras.txt",sep=",",what=character)
palabritas <- scan("~//Documentos/quitarpalabras.txt", what=character)
palabritas <- scan("~//Documentos/quitarpalabras.txt", what=character)
palabritas <- scan("~//Documentos/quitarpalabras.txt")
palabritas <- readLines("~//Documentos/quitarpalabras.txt")
palabritas
?readLines
palabritas <- readLines("~//Documentos/quitarpalabras.txt", encoding= UTF-8)
palabritas <- readLines("~//Documentos/quitarpalabras.txt", encoding= "UTF-8")
palabritas
palabritas <- scan("~//Documentos/quitarpalabras.txt", what=character, sep=",")
palabritas <- scan("~//Documentos/quitarpalabras.txt", sep=",")
save (quitarpalabras,file="~//Documentos/quitarpalabras1.rdata")
rm (quitarpalabras)
load("~//Documentos/quitarpalabras1.rdata")
quitarpalabras
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS", "and", "the")
docs <- tm_map(docs, removeWords, quitarpalabras)
tdm <- TermDocumentMatrix(docs)
freq <- rowSums(as.matrix(tdm))
length(freq)
ord <- order(freq)
freq[tail(ord)]
freq[tail(ord,20)]
docs <- tm_map(docs, stripWhitespace)
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS", "and", "the")
ocs <- tm_map(docs, removeWords, quitarpalabras)
#Specific transformations
#for (j in seq(docs))
#{
#        docs[[j]] <- gsub("turístico", "turística", docs[[j]])
#        docs[[j]] <- gsub("turísticos", "turística", docs[[j]])
#        docs[[j]] <- gsub("turísticas", "turística", docs[[j]])
#}
##Stemming
#docs2 <- tm_map(docs, stemDocument, language = "spanish")
##We use TermDocumentMatrix()
##to create the matrix:
tdm <- TermDocumentMatrix(docs)
freq <- rowSums(as.matrix(tdm))
length(freq)
#By ordering the frequencies we can list the most frequent terms and the
#least frequent terms:
ord <- order(freq)
# Least frequent terms
freq[head(ord)]
# Most frequent terms
freq[tail(ord)]
freq[tail(ord,20)]
head(table(freq), 15)
tail(table(freq), 15)
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS", "and", "the", " teoría" " praxis")
docs <- tm_map(docs, removeWords, quitarpalabras)
tdm <- TermDocumentMatrix(docs)
##we select a subset of inspect.
inspect(tdm[5:10, 740:743])
#We can obtain the term frequencies as a vector by converting the
#term document matrix into a matrix and summing the column counts:
freq <- rowSums(as.matrix(tdm))
length(freq)
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS", "and", "the", " teoría" " praxis")
docs <- tm_map(docs, removeWords, quitarpalabras)
quitarpalabras <- c("Teoría y Praxis", "teoría", "praxis", "RESUMEN", "TEORÍA Y PRAXIS", "FUENTES CONSULTADAS", "and", "the", " teoría", " praxis")
docs <- tm_map(docs, removeWords, quitarpalabras)
rm ocs
rm (ocs)
docs <- tm_map(docs, removeWords, quitarpalabras)
tdm <- TermDocumentMatrix(docs)
freq <- rowSums(as.matrix(tdm))
length(freq)
ord <- order(freq)
freq[head(ord)]
tail(table(freq), 15)
freq[tail(ord)]
m <- as.matrix(tdm)
#To write the data to file.
dim(m)
write.csv(m, file="~//Documentos/teoriaypraxis.csv")
tdms <- removeSparseTerms(tdm, 0.2)
dim(dtms)
dim(tdms)
freq <- rowSums(as.matrix(tdms))
freq
freq <- colSums(as.matrix(tdms))
freq
freq <- rowSums(as.matrix(tdms))
freq
tdms <- removeSparseTerms(tdm, 0.1)
dim(tdms)
tdms <- removeSparseTerms(tdm, 0.5)
dim(tdms)
tdms <- removeSparseTerms(tdm, 0.8)
dim(tdms)
freq <- rowSums(as.matrix(tdms))
freq
dim(tdms)
dim(tdm)
tdms <- removeSparseTerms(tdm, 0.9)
dim(tdms)
tdms <- removeSparseTerms(tdm, 0.95)
dim(tdms)
freq <- rowSums(as.matrix(tdms))
freq
tdms <- removeSparseTerms(tdm, 0.8)
dim(tdms)
dbinom(1,5,0.1)
dbinom(2,10,0.1)
sum(dbinom(4:20,20,0.1))
sum(dbinom(5:25,25,0.1))
sum(dbinom(6:30,30,0.1))
sum(dbinom(7:35,35,0.1))
sum(dbinom(8:40,40,0.1))
sum(dbinom(1:86,86,0.01))
sum(dbinom(10:86,86,0.01))
sum(dbinom(2:86,86,0.01))
sum(dbinom(3:86,86,0.01))
sum(dbinom(4:86,86,0.01))
sum(dbinom(5:86,86,0.01))
dbinom(1,5,0.1)
dbinom(1,5,0.2)
dbinom(2,10,0.1)
BaseDatos2 <- read.csv("~/Documentos/Dropbox/DireccionyTutoria/Carolina Rodriguez/base de datos caro/BaseDatos2.csv")
View(BaseDatos2)
summary(BaseDatos2)
BDok <- (BaseDatos2[-1,])
BDok <- (BaseDatos2[,-1])
fit <- princomp(BDok, cor=TRUE)
summary(fit) # print variance accounted for
loadings(fit) # pc loadings
plot(fit,type="lines") # scree plot
fit$scores # the principal components
biplot(fit)
install.packages("psych")
library(psych)
fit <- principal(mydata, nfactors=5, rotate="varimax")
fit <- principal(BDok, nfactors=5, rotate="varimax")
install.packages("GPArotation")
fit <- principal(BDok, nfactors=5, rotate="varimax")
fit # print results
fit3 <- factanal(BDok, 3, rotation="varimax")
print(fit3, digits=2, cutoff=.3, sort=TRUE)
load <- fit3$loadings[,1:2]
plot(load,type="n") # set up plot
text(load,labels=names(BDok),cex=.7) # add variable names
fit4 <- factor.pa(BDok, nfactors=3, rotation="varimax")
library(nFactors)
install.packages("nFactors")
library(nFactors)
ev <- eigen(cor(BDok)) # get eigenvalues
ap <- parallel(subject=nrow(BDok),var=ncol(BDok),
rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
install.packages("FactoMineR")
library(FactoMineR)
result <- PCA(BDok) # graphs generated automatically
?factor.pa
STAKEHOLDERSTRESGRUPOS <- read.csv("~/Documentos/Dropbox/DireccionyTutoria/Carolina Rodriguez/base de datos caro/STAKEHOLDERSTRESGRUPOS.csv")
View(STAKEHOLDERSTRESGRUPOS)
BDok <- (STAKEHOLDERSTRESGRUPOS[,-1])
library(nFactors)
ev <- eigen(cor(BDok)) # get eigenvalues
ap <- parallel(subject=nrow(BDok),var=ncol(BDok),
rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
fit3 <- factanal(BDok, 14, rotation="varimax")
print(fit3, digits=2, cutoff=.3, sort=TRUE)
STAKEHOLDERSTRESGRUPOS <- read.csv("~/Documentos/Dropbox/DireccionyTutoria/Carolina Rodriguez/base de datos caro/STAKEHOLDERSTRESGRUPOS.csv")
BDok <- (STAKEHOLDERSTRESGRUPOS[,-1])
library(nFactors)
ev <- eigen(cor(BDok)) # get eigenvalues
ap <- parallel(subject=nrow(BDok),var=ncol(BDok),
rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
fit3 <- factanal(BDok, 14, rotation="varimax")
print(fit3, digits=2, cutoff=.3, sort=TRUE)
load <- fit3$loadings[,1:2]
plot(load,type="n") # set up plot
text(load,labels=names(BDok),cex=.7) # add variable names
bd <- (fit3, digits=2, cutoff=.3, sort=TRUE)
bd <- print(fit3, digits=2, cutoff=.3, sort=TRUE)
?save
save(bd, file="matrizfactores")
save(as.data.frame(bd, file="matrizfactores"))
save(as.data.frame(bd), file="matrizfactores")
bd2 <- as.data.frame(bd)
loadings
fit3$loadings
?file
bd <- file("matrizfactores2", "w")
print(fit3, digits=2, cutoff=.3, sort=TRUE)
close(bd)
print(fit3, digits=2, cutoff=.3, sort=TRUE)
STAKEHOLDERSTRESGRUPOS <- read.csv("~/Documentos/Dropbox/DireccionyTutoria/Carolina Rodriguez/base de datos caro/STAKEHOLDERSTRESGRUPOS.csv")
BDok <- (STAKEHOLDERSTRESGRUPOS[,-1])
fit3 <- factanal(BDok, 10, rotation="varimax")
print(fit3, digits=2, cutoff=.3, sort=TRUE)
print(fit3, digits=2, cutoff=.3, sort=TRUE)
NEI <- readRDS("summarySCC_PM25.rds")
setwd("~/Documentos/Rexercises")
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
table (SCC)
s1 <- NEI[sample(nrow(NEI), 1000, replace = FALSE),]
with (s1, plot(as.factor(year), Emissions, ylim = c(0,200), main="Emissions by year"))
m1  = lm(year ~ Emissions, data = s1)
years <- c(1999,2002,2005,2008)
Emmissions <- c(sum(s1[s1$year == 1999,4]),sum(s1[s1$year == 2002,4]),
sum(s1[s1$year == 2005,4]),sum(s1[s1$year == 2008,4]))
Emybyyear <- data.frame(years, Emmissions)
plot (years,Emmissions,main="Emissions in the USA", xlab="year", ylab="Emissions in tons",type="l")
Emmissions <- c(mean(s1[s1$year == 1999,4]),mean(s1[s1$year == 2002,4]),
mean(s1[s1$year == 2005,4]),mean(s1[s1$year == 2008,4]))
Emybyyear <- data.frame(years, Emmissions)
plot (years,Emmissions,main="Emissions in the USA", xlab="year", ylab="Emissions in tons",type="l")
modelito <- lm(Emmissions ~ years, data = Emybyyear)
abline(modelito, col="blue")
abline(modelito, col="blue")
with (s1, plot(year, Emissions, ylim = c(0,200), main="Emissions by year"))
abline(modelito, col="blue")
Emmissions <- c(mean(log(s1[s1$year == 1999,4])),mean(log(s1[s1$year == 2002,4])),
mean(log(s1[s1$year == 2005,4])),mean(log(s1[s1$year == 2008,4])))
plot (years,Emmissions,main="Emissions in the USA", xlab="year", ylab="Emissions in tons",type="l")
mean(log(s1$Emissions))
Emmissions <- c(mean(s1[s1$year == 1999,4],trim=0.1),mean(s1[s1$year == 2002,4],trim=0.1),
mean(s1[s1$year == 2005,4],trim=0.1),mean(s1[s1$year == 2008,4],trim=0.1))
plot (years,Emmissions,main="Emissions in the USA", xlab="year", ylab="Emissions in tons",type="l")
modelito <- lm(Emmissions ~ years, data = Emybyyear)
abline(modelito, col="blue")
Emybyyear <- data.frame(years, Emmissions)
modelito <- lm(Emmissions ~ years, data = Emybyyear)
abline(modelito, col="blue")
remove s1
remove "s1"
remove m1
remove "m1"
remove "modelito"
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
s1 <- NEI[sample(nrow(NEI), 1000, replace = FALSE),]
Emissions <- c(mean(s1[s1$year == 1999,4],trim=0.1),mean(s1[s1$year == 2002,4],trim=0.1),
mean(s1[s1$year == 2005,4],trim=0.1),mean(s1[s1$year == 2008,4],trim=0.1))
years <- c(1999,2002,2005,2008)
Emybyyear <- data.frame(years, Emissions)
modelito <- lm(Emissions ~ years, data = Emybyyear)
par(mfrow =c(1,2))
with(s1, plot(year, Emissions, ylim = c(0,200), main="Emissions by year"))
plot (years,Emmissions,main="Emissions in the USA", xlab="year", ylab="Emissions in tons",type="l")
plot (years,Emissions,main="Emissions in the USA", xlab="year", ylab="Emissions in tons",type="l")
abline(modelito, col="blue")
mtext("Emissions by year in the USA")
par(mfrow =c(1,2))
with(s1,{ plot(year, Emissions, ylim = c(0,200), main="Emissions by year"))
mtext("Emissions by year in the USA")}
with(s1,{ plot(year, Emissions, ylim = c(0,200), main="Emissions by year")
mtext("Emissions by year in the USA")})
with(s1,{ plot(year, Emissions, ylim = c(0,200), main="Emissions by year")
mtext("Emissions by year in the USA", outer = TRUE)})
par(mfrow =c(1,2))
with(s1,{ plot(year, Emissions, ylim = c(0,200), main="Emissions by year")
mtext("Emissions by year in the USA", outer = TRUE)})
par("omar")
par("oma")
par("mar")
par(mfrow =c(1,2), oma = c(0,0,2,0))
with(s1,{ plot(year, Emissions, ylim = c(0,200), main="Emissions by year")
mtext("Emissions by year in the USA", outer = TRUE)})
plot (years,Emissions,main="Mean of Emissions by year", xlab="year", ylab="Mean in tons",type="l")
abline(modelito, col="blue")
legend("topright", pch = 2, col =("blue"),legend = ("Tendency"))
legend("topright", pch = 8, col =("blue"),legend = ("Tendency"))
legend("topright", pch = -, col =("blue"),legend = ("Tendency"))
legend("topright", pch = "-", col =("blue"),legend = ("Tendency"))
legend("topright", pch = "-", col =("blue"),legend = ("tendency"))
remove (modelito)
remove (Emissions)
remove (years)
remove (s1)
remove (Emybyyear)
########### Base completa
Emissions <- c(mean(NEI[NEI$year == 1999,4],trim=0.1),mean(NEI[NEI$year == 2002,4],trim=0.1),
mean(NEI[NEI$year == 2005,4],trim=0.1),mean(NEI[NEI$year == 2008,4],trim=0.1))
years <- c(1999,2002,2005,2008)
Emybyyear <- data.frame(years, Emissions)
modelito <- lm(Emissions ~ years, data = Emybyyear)
########### Plots para base completa
par(mfrow =c(1,2), oma = c(0,0,2,0))
with(NEI,{ plot(year, Emissions, ylim = c(0,10000), main="Every fip by year", xlab="Year", ylab="Emissions in tons")
mtext("Emissions by year in the USA", outer = TRUE)})
plot (years,Emissions,main="Mean of emissions by year", xlab="year", ylab="Mean in tons",type="l")
abline(modelito, col="blue")
legend("topright", pch = "-", col =("blue"),legend = ("tendency"))
######### FIN
max(NEI$Emissions)
quantile(NEI$Emissions, 0.9)
quantile(NEI$Emissions, 0.99)
quantile(NEI$Emissions, 0.999)
quantile(NEI$Emissions, 0.9999)
quantile(NEI$Emissions, 0.99999)
quantile(NEI$Emissions, 0.9999999)
par(mfrow =c(1,2), oma = c(0,0,2,0))
with(NEI,{ plot(year, Emissions, ylim = c(0,100000), main="Every fip by year", xlab="Year", ylab="Emissions in tons")
mtext("Emissions by year in the USA", outer = TRUE)})
plot (years,Emissions,main="Mean of emissions by year", xlab="year", ylab="Mean in tons",type="l")
abline(modelito, col="blue")
legend("topright", pch = "-", col =("blue"),legend = ("tendency"))
summary(NEI[NEI$fips == 24510,Emissions])
summary(NEI[NEI$fips == "24510",Emissions])
summary(NEI$fips)
summary(NEI$fips=="24510")
Baltimore <- NEI[NEI$fips=="24510",]
Emissions <- c(mean(s1[s1$year == 1999,4],trim=0.1),mean(s1[s1$year == 2002,4],trim=0.1),
mean(s1[s1$year == 2005,4],trim=0.1),mean(s1[s1$year == 2008,4],trim=0.1))
years <- c(1999,2002,2005,2008)
Emybyyear <- data.frame(years, Emissions)
modelBal <- lm(Emissions ~ years, data = Emybyyear)
############## Plots para subset
par(mfrow =c(1,2), oma = c(0,0,2,0))
with(Baltimore,{ plot(year, Emissions, ylim = c(0,200), main="Every fip by year", xlab="Year", ylab="Emissions in tons")
mtext("Emissions by year in Baltimore, Maryland", outer = TRUE)})
plot (years,Emissions,main="Mean of emissions by year", xlab="year", ylab="Mean in tons",type="l")
abline(modelBal, col="blue")
legend("topright", pch = "-", col =("red"),legend = ("tendency"))
par(mfrow =c(1,2), oma = c(0,0,2,0))
with(Baltimore,{ plot(year, Emissions, ylim = c(0,200), main="Every fip by year", xlab="Year", ylab="Emissions in tons")
mtext("Emissions by year in Baltimore, Maryland", outer = TRUE)})
plot (years,Emissions,main="Mean of emissions by year", xlab="year", ylab="Mean in tons",type="l")
abline(modelBal, col="red")
legend("topright", pch = "-", col =("red"),legend = ("tendency"))
library("ggplot2", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.1")
table(Baltimore$Emissions ~ Baltimore$type)
table(Baltimore$Emissions,Baltimore$type)
table(Baltimore$type,Baltimore$Emissions)
g <- ggplot(Baltimore, aes(Emissions, type, year))
p <- g + geom_point()
print(p)
g <- ggplot(Baltimore, aes(type, Emissions, year))
p <- g + geom_point()
print(p)
g <- ggplot(Baltimore, aes(year, Emissions, type))
p <- g + geom_point()
print(p)
g <- ggplot(Baltimore, aes(year, Emissions, type))
p <- g + geom_point() + geom_smooth()
print(p)
p <- g + geom_point() + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + facet_grid(. ~ type) + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 500)) + facet_grid(. ~ type) + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 300)) + facet_grid(. ~ type) + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 100)) + facet_grid(. ~ type) + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 75)) + facet_grid(. ~ type) + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 10)) + facet_grid(. ~ type) + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 70)) + facet_grid(. ~ type) + geom_smooth(method="lm")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 70)) + facet_grid(. ~ type) + geom_smooth(method="lm")
+ labs(title="Emissions by type in Baltimore, Maryland")
+ labs(y="Emissions in tons")
print(p)
p <- g + geom_point() + coord_cartesian(ylim = c(0, 70)) + facet_grid(. ~ type) + geom_smooth(method="lm") + labs(title="Emissions by type in Baltimore, Maryland") + labs(y="Emissions in tons")
print(p)
remove(Emissions)
remove(modelBal)
remove(modelito)
remove (Emybyyear)
remove(years)
remove(g)
remove(p)
table(SCC$SCC.Level.One)
table(SCC$Data.Category)
table(SCC$Short.Name)
table(SCC$EI.Sector)
table(SCC$Option.Group)
table(SCC$Option.Set)
table(SCC$SCC.Level.Two)
table(as.factor(Baltimore$SCC))
summary(as.factor(Baltimore$SCC))
head(SCC)
View(SCC)
print (SCC$SCC=="10500102")
print (SCC[SCC$SCC=="10500102",])
print (SCC[SCC$SCC=="10500202",])
